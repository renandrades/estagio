{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column T has 8 (1.8%) null values\n",
      "Column P has 22 (4.9%) null values\n",
      "Column QRST has 1 (0.2%) null values\n",
      "Column J has 374 (83.1%) null values\n",
      "Column heart_rate has 1 (0.2%) null values\n",
      "Column S'_wave has a single value and will be discarded\n",
      "Column CB has a single value and will be discarded\n",
      "Column CD has a single value and will be discarded\n",
      "Column CI has a single value and will be discarded\n",
      "Column CS has a single value and will be discarded\n",
      "Column EV has a single value and will be discarded\n",
      "Column EY has a single value and will be discarded\n",
      "Column FF has a single value and will be discarded\n",
      "Column FH has a single value and will be discarded\n",
      "Column FJ has a single value and will be discarded\n",
      "Column FL has a single value and will be discarded\n",
      "Column FS has a single value and will be discarded\n",
      "Column FZ has a single value and will be discarded\n",
      "Column GA has a single value and will be discarded\n",
      "Column GH has a single value and will be discarded\n",
      "Column IB has a single value and will be discarded\n",
      "Column KP has a single value and will be discarded\n",
      "Column LC has a single value and will be discarded\n",
      "\n",
      "Banco com 450 amostras e 262 colunas\n",
      "\n",
      "Tabela sumarizando as colunas do banco\n",
      "\n",
      "              age         sex      height      weight  qrs_duration  \\\n",
      "count  450.000000  450.000000  450.000000  450.000000    450.000000   \n",
      "mean    46.675556    0.551111  163.842222   68.437778     88.942222   \n",
      "std     16.214228    0.497934   10.412195   16.132715     15.394913   \n",
      "min      1.000000    0.000000  105.000000   10.000000     55.000000   \n",
      "25%     36.000000    0.000000  160.000000   59.000000     80.000000   \n",
      "50%     47.000000    1.000000  164.000000   68.000000     86.500000   \n",
      "75%     58.000000    1.000000  170.000000   79.000000     94.000000   \n",
      "max     83.000000    1.000000  190.000000  176.000000    188.000000   \n",
      "\n",
      "       p-r_interval  q-t_interval  t_interval  p_interval         qrs  ...  \\\n",
      "count    450.000000    450.000000  450.000000  450.000000  450.000000  ...   \n",
      "mean     155.195556    367.797778  170.086667   90.035556   33.353333  ...   \n",
      "std       44.918555     32.260307   35.644734   25.834294   45.254362  ...   \n",
      "min        0.000000    240.000000  108.000000    0.000000 -172.000000  ...   \n",
      "25%      142.000000    350.000000  148.000000   79.000000    3.250000  ...   \n",
      "50%      157.000000    367.500000  162.000000   91.000000   40.000000  ...   \n",
      "75%      175.000000    384.000000  179.000000  102.000000   66.000000  ...   \n",
      "max      524.000000    509.000000  381.000000  205.000000  169.000000  ...   \n",
      "\n",
      "               KV          KY          KZ          LA          LB          LD  \\\n",
      "count  450.000000  450.000000  450.000000  450.000000  450.000000  450.000000   \n",
      "mean    -0.309111   -0.278667    9.067111   -1.441333    0.004000    0.513111   \n",
      "std      0.594654    0.549580    3.468655    1.992218    0.050229    0.346322   \n",
      "min     -5.600000   -4.100000    0.000000  -28.600000    0.000000   -0.800000   \n",
      "25%     -0.500000   -0.400000    6.600000   -2.100000    0.000000    0.400000   \n",
      "50%     -0.200000    0.000000    8.800000   -1.100000    0.000000    0.500000   \n",
      "75%      0.000000    0.000000   11.200000    0.000000    0.000000    0.700000   \n",
      "max      2.700000    0.000000   23.600000    0.000000    0.800000    2.400000   \n",
      "\n",
      "               LE          LF          LG   diagnosis  \n",
      "count  450.000000  450.000000  450.000000  450.000000  \n",
      "mean     1.220667   19.432222   29.588222    0.455556  \n",
      "std      1.427738   13.430692   18.453662    0.498575  \n",
      "min     -6.000000  -44.200000  -38.600000    0.000000  \n",
      "25%      0.500000   11.500000   17.725000    0.000000  \n",
      "50%      1.350000   18.150000   28.100000    0.000000  \n",
      "75%      2.100000   25.875000   41.175000    1.000000  \n",
      "max      6.000000   88.800000  115.900000    1.000000  \n",
      "\n",
      "[8 rows x 262 columns]\n",
      "Testing Random Forests\n",
      "1 10 2 2 0.67 0.62\n",
      "1 10 2 4 0.69 0.62\n",
      "1 10 2 8 0.66 0.56\n",
      "1 10 2 16 0.72 0.64\n",
      "1 10 2 32 0.71 0.62\n",
      "1 10 4 2 0.71 0.65\n",
      "1 10 4 4 0.72 0.65\n",
      "1 10 4 8 0.66 0.57\n",
      "1 10 4 16 0.72 0.58\n",
      "1 10 4 32 0.66 0.65\n",
      "1 10 6 2 0.72 0.67\n",
      "1 10 6 4 0.69 0.66\n",
      "1 10 6 8 0.70 0.65\n",
      "1 10 6 16 0.72 0.67\n",
      "1 10 6 32 0.72 0.66\n",
      "1 10 8 2 0.71 0.68\n",
      "1 10 8 4 0.70 0.71\n",
      "1 10 8 8 0.67 0.64\n",
      "1 10 8 16 0.69 0.71\n",
      "1 10 8 32 0.72 0.65\n",
      "1 10 10 2 0.73 0.65\n",
      "1 10 10 4 0.73 0.69\n",
      "1 10 10 8 0.70 0.65\n",
      "1 10 10 16 0.70 0.69\n",
      "1 10 10 32 0.72 0.65\n",
      "1 10 15 2 0.73 0.74\n",
      "1 10 15 4 0.68 0.66\n",
      "1 10 15 8 0.71 0.70\n",
      "1 10 15 16 0.72 0.64\n",
      "1 10 15 32 0.76 0.75\n",
      "1 10 25 2 0.72 0.67\n",
      "1 10 25 4 0.72 0.70\n",
      "1 10 25 8 0.74 0.69\n",
      "1 10 25 16 0.74 0.68\n",
      "1 10 25 32 0.73 0.66\n",
      "1 10 50 2 0.75 0.70\n",
      "1 10 50 4 0.71 0.69\n",
      "1 10 50 8 0.71 0.70\n",
      "1 10 50 16 0.72 0.69\n",
      "1 10 50 32 0.72 0.69\n",
      "1 10 auto 2 0.71 0.67\n",
      "1 10 auto 4 0.72 0.67\n",
      "1 10 auto 8 0.71 0.67\n",
      "1 10 auto 16 0.70 0.67\n",
      "1 10 auto 32 0.72 0.69\n",
      "[0.72058824 0.69117647 0.69117647 0.71641791 0.56060606]\n",
      "1 25 2 2 0.69 0.65\n",
      "1 25 2 4 0.68 0.60\n",
      "1 25 2 8 0.72 0.63\n",
      "1 25 2 16 0.68 0.64\n",
      "1 25 2 32 0.65 0.65\n",
      "1 25 4 2 0.67 0.65\n",
      "1 25 4 4 0.72 0.69\n",
      "1 25 4 8 0.70 0.67\n",
      "1 25 4 16 0.72 0.68\n",
      "1 25 4 32 0.70 0.69\n",
      "1 25 6 2 0.67 0.64\n",
      "1 25 6 4 0.73 0.67\n",
      "1 25 6 8 0.67 0.66\n",
      "1 25 6 16 0.72 0.68\n",
      "1 25 6 32 0.74 0.64\n",
      "1 25 8 2 0.72 0.71\n",
      "1 25 8 4 0.71 0.71\n",
      "1 25 8 8 0.72 0.67\n",
      "1 25 8 16 0.73 0.68\n",
      "1 25 8 32 0.71 0.67\n",
      "1 25 10 2 0.72 0.63\n",
      "1 25 10 4 0.75 0.66\n",
      "1 25 10 8 0.76 0.73\n",
      "1 25 10 16 0.70 0.66\n",
      "1 25 10 32 0.75 0.72\n",
      "1 25 15 2 0.73 0.68\n",
      "1 25 15 4 0.75 0.69\n",
      "1 25 15 8 0.73 0.65\n",
      "1 25 15 16 0.72 0.71\n",
      "1 25 15 32 0.74 0.68\n",
      "1 25 25 2 0.70 0.67\n",
      "1 25 25 4 0.75 0.70\n",
      "1 25 25 8 0.74 0.70\n",
      "1 25 25 16 0.75 0.69\n",
      "1 25 25 32 0.73 0.66\n",
      "1 25 50 2 0.74 0.73\n",
      "1 25 50 4 0.73 0.70\n",
      "1 25 50 8 0.76 0.73\n",
      "1 25 50 16 0.74 0.70\n",
      "1 25 50 32 0.72 0.69\n",
      "1 25 auto 2 0.74 0.69\n",
      "1 25 auto 4 0.73 0.70\n",
      "1 25 auto 8 0.74 0.70\n",
      "1 25 auto 16 0.72 0.69\n",
      "1 25 auto 32 0.71 0.68\n",
      "[0.72058824 0.69117647 0.76470588 0.74626866 0.62121212]\n",
      "1 50 2 2 0.68 0.59\n",
      "1 50 2 4 0.68 0.63\n",
      "1 50 2 8 0.70 0.67\n",
      "1 50 2 16 0.67 0.60\n",
      "1 50 2 32 0.65 0.61\n",
      "1 50 4 2 0.72 0.67\n",
      "1 50 4 4 0.71 0.66\n",
      "1 50 4 8 0.74 0.69\n",
      "1 50 4 16 0.66 0.61\n",
      "1 50 4 32 0.69 0.65\n",
      "1 50 6 2 0.72 0.68\n",
      "1 50 6 4 0.70 0.65\n",
      "1 50 6 8 0.71 0.71\n",
      "1 50 6 16 0.72 0.68\n",
      "1 50 6 32 0.72 0.70\n",
      "1 50 8 2 0.73 0.70\n",
      "1 50 8 4 0.70 0.65\n",
      "1 50 8 8 0.71 0.67\n",
      "1 50 8 16 0.70 0.65\n",
      "1 50 8 32 0.74 0.70\n",
      "1 50 10 2 0.73 0.70\n",
      "1 50 10 4 0.72 0.69\n",
      "1 50 10 8 0.75 0.74\n",
      "1 50 10 16 0.74 0.70\n",
      "1 50 10 32 0.75 0.68\n",
      "1 50 15 2 0.75 0.70\n",
      "1 50 15 4 0.74 0.68\n",
      "1 50 15 8 0.77 0.72\n",
      "1 50 15 16 0.76 0.67\n",
      "1 50 15 32 0.75 0.70\n",
      "1 50 25 2 0.73 0.71\n",
      "1 50 25 4 0.76 0.73\n",
      "1 50 25 8 0.74 0.67\n",
      "1 50 25 16 0.75 0.69\n",
      "1 50 25 32 0.76 0.67\n",
      "1 50 50 2 0.72 0.72\n",
      "1 50 50 4 0.75 0.72\n",
      "1 50 50 8 0.73 0.72\n",
      "1 50 50 16 0.74 0.72\n",
      "1 50 50 32 0.74 0.69\n",
      "1 50 auto 2 0.74 0.71\n",
      "1 50 auto 4 0.75 0.73\n",
      "1 50 auto 8 0.74 0.70\n",
      "1 50 auto 16 0.76 0.73\n",
      "1 50 auto 32 0.76 0.67\n",
      "[0.75       0.67647059 0.75       0.76119403 0.65151515]\n",
      "1 100 2 2 0.69 0.66\n",
      "1 100 2 4 0.68 0.61\n",
      "1 100 2 8 0.68 0.62\n",
      "1 100 2 16 0.68 0.64\n",
      "1 100 2 32 0.68 0.68\n",
      "1 100 4 2 0.70 0.66\n",
      "1 100 4 4 0.70 0.62\n",
      "1 100 4 8 0.71 0.67\n",
      "1 100 4 16 0.70 0.66\n",
      "1 100 4 32 0.73 0.70\n",
      "1 100 6 2 0.74 0.67\n",
      "1 100 6 4 0.72 0.68\n",
      "1 100 6 8 0.71 0.65\n",
      "1 100 6 16 0.74 0.70\n",
      "1 100 6 32 0.74 0.70\n",
      "1 100 8 2 0.72 0.68\n",
      "1 100 8 4 0.73 0.71\n",
      "1 100 8 8 0.73 0.66\n",
      "1 100 8 16 0.72 0.68\n",
      "1 100 8 32 0.73 0.70\n",
      "1 100 10 2 0.72 0.70\n",
      "1 100 10 4 0.76 0.69\n",
      "1 100 10 8 0.74 0.70\n",
      "1 100 10 16 0.74 0.68\n",
      "1 100 10 32 0.73 0.69\n",
      "1 100 15 2 0.74 0.71\n",
      "1 100 15 4 0.74 0.70\n",
      "1 100 15 8 0.75 0.70\n",
      "1 100 15 16 0.74 0.70\n",
      "1 100 15 32 0.75 0.67\n",
      "1 100 25 2 0.75 0.71\n",
      "1 100 25 4 0.75 0.70\n",
      "1 100 25 8 0.76 0.71\n",
      "1 100 25 16 0.75 0.71\n",
      "1 100 25 32 0.74 0.71\n",
      "1 100 50 2 0.74 0.72\n",
      "1 100 50 4 0.72 0.72\n",
      "1 100 50 8 0.74 0.70\n",
      "1 100 50 16 0.74 0.72\n",
      "1 100 50 32 0.74 0.69\n",
      "1 100 auto 2 0.76 0.71\n",
      "1 100 auto 4 0.74 0.68\n",
      "1 100 auto 8 0.74 0.69\n",
      "1 100 auto 16 0.75 0.69\n",
      "1 100 auto 32 0.75 0.70\n",
      "[0.73529412 0.69117647 0.75       0.7761194  0.66666667]\n",
      "1 200 2 2 0.67 0.58\n",
      "1 200 2 4 0.69 0.64\n",
      "1 200 2 8 0.69 0.62\n",
      "1 200 2 16 0.68 0.61\n",
      "1 200 2 32 0.66 0.63\n",
      "1 200 4 2 0.71 0.65\n",
      "1 200 4 4 0.71 0.68\n",
      "1 200 4 8 0.71 0.68\n",
      "1 200 4 16 0.73 0.67\n",
      "1 200 4 32 0.70 0.63\n",
      "1 200 6 2 0.73 0.70\n",
      "1 200 6 4 0.71 0.67\n",
      "1 200 6 8 0.72 0.72\n",
      "1 200 6 16 0.72 0.66\n",
      "1 200 6 32 0.72 0.70\n",
      "1 200 8 2 0.74 0.70\n",
      "1 200 8 4 0.74 0.70\n",
      "1 200 8 8 0.74 0.70\n",
      "1 200 8 16 0.73 0.68\n",
      "1 200 8 32 0.73 0.70\n",
      "1 200 10 2 0.74 0.69\n",
      "1 200 10 4 0.74 0.70\n",
      "1 200 10 8 0.74 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 200 10 16 0.74 0.67\n",
      "1 200 10 32 0.75 0.71\n",
      "1 200 15 2 0.75 0.70\n",
      "1 200 15 4 0.76 0.70\n",
      "1 200 15 8 0.75 0.71\n",
      "1 200 15 16 0.75 0.71\n",
      "1 200 15 32 0.75 0.73\n",
      "1 200 25 2 0.75 0.69\n",
      "1 200 25 4 0.75 0.70\n",
      "1 200 25 8 0.75 0.70\n",
      "1 200 25 16 0.74 0.72\n",
      "1 200 25 32 0.75 0.69\n",
      "1 200 50 2 0.74 0.71\n",
      "1 200 50 4 0.74 0.71\n",
      "1 200 50 8 0.73 0.71\n",
      "1 200 50 16 0.74 0.73\n",
      "1 200 50 32 0.73 0.71\n",
      "1 200 auto 2 0.75 0.71\n",
      "1 200 auto 4 0.74 0.67\n",
      "1 200 auto 8 0.74 0.70\n",
      "1 200 auto 16 0.75 0.70\n",
      "1 200 auto 32 0.75 0.70\n",
      "[0.70588235 0.70588235 0.72058824 0.7761194  0.65151515]\n",
      "2 10 2 2 0.74 0.71\n",
      "2 10 2 4 0.73 0.70\n",
      "2 10 2 8 0.69 0.67\n",
      "2 10 2 16 0.77 0.72\n",
      "2 10 2 32 0.69 0.72\n",
      "2 10 4 2 0.79 0.70\n",
      "2 10 4 4 0.76 0.64\n",
      "2 10 4 8 0.70 0.66\n",
      "2 10 4 16 0.78 0.66\n",
      "2 10 4 32 0.72 0.72\n",
      "2 10 6 2 0.76 0.68\n",
      "2 10 6 4 0.77 0.69\n",
      "2 10 6 8 0.74 0.72\n",
      "2 10 6 16 0.76 0.68\n",
      "2 10 6 32 0.76 0.71\n",
      "2 10 8 2 0.81 0.71\n",
      "2 10 8 4 0.77 0.71\n",
      "2 10 8 8 0.79 0.65\n",
      "2 10 8 16 0.76 0.70\n",
      "2 10 8 32 0.78 0.71\n",
      "2 10 10 2 0.80 0.75\n",
      "2 10 10 4 0.77 0.73\n",
      "2 10 10 8 0.77 0.72\n",
      "2 10 10 16 0.80 0.68\n",
      "2 10 10 32 0.77 0.76\n",
      "2 10 15 2 0.78 0.67\n",
      "2 10 15 4 0.80 0.74\n",
      "2 10 15 8 0.77 0.73\n",
      "2 10 15 16 0.76 0.65\n",
      "2 10 15 32 0.78 0.71\n",
      "2 10 25 2 0.78 0.70\n",
      "2 10 25 4 0.80 0.72\n",
      "2 10 25 8 0.79 0.72\n",
      "2 10 25 16 0.77 0.73\n",
      "2 10 25 32 0.79 0.77\n",
      "2 10 50 2 0.81 0.68\n",
      "2 10 50 4 0.79 0.73\n",
      "2 10 50 8 0.78 0.72\n",
      "2 10 50 16 0.84 0.81\n",
      "2 10 50 32 0.80 0.75\n",
      "2 10 auto 2 0.79 0.72\n",
      "2 10 auto 4 0.75 0.66\n",
      "2 10 auto 8 0.81 0.79\n",
      "2 10 auto 16 0.80 0.79\n",
      "2 10 auto 32 0.75 0.69\n",
      "[0.70588235 0.69117647 0.77941176 0.68656716 0.57575758]\n",
      "2 25 2 2 0.72 0.66\n",
      "2 25 2 4 0.75 0.67\n",
      "2 25 2 8 0.74 0.65\n",
      "2 25 2 16 0.75 0.70\n",
      "2 25 2 32 0.77 0.71\n",
      "2 25 4 2 0.76 0.72\n",
      "2 25 4 4 0.77 0.73\n",
      "2 25 4 8 0.75 0.70\n",
      "2 25 4 16 0.80 0.73\n",
      "2 25 4 32 0.73 0.73\n",
      "2 25 6 2 0.77 0.73\n",
      "2 25 6 4 0.77 0.70\n",
      "2 25 6 8 0.75 0.70\n",
      "2 25 6 16 0.78 0.75\n",
      "2 25 6 32 0.74 0.70\n",
      "2 25 8 2 0.75 0.72\n",
      "2 25 8 4 0.77 0.73\n",
      "2 25 8 8 0.77 0.69\n",
      "2 25 8 16 0.80 0.77\n",
      "2 25 8 32 0.74 0.68\n",
      "2 25 10 2 0.77 0.68\n",
      "2 25 10 4 0.76 0.75\n",
      "2 25 10 8 0.75 0.73\n",
      "2 25 10 16 0.75 0.71\n",
      "2 25 10 32 0.79 0.73\n",
      "2 25 15 2 0.82 0.80\n",
      "2 25 15 4 0.80 0.73\n",
      "2 25 15 8 0.81 0.73\n",
      "2 25 15 16 0.77 0.69\n",
      "2 25 15 32 0.80 0.71\n",
      "2 25 25 2 0.77 0.78\n",
      "2 25 25 4 0.81 0.73\n",
      "2 25 25 8 0.82 0.73\n",
      "2 25 25 16 0.79 0.73\n",
      "2 25 25 32 0.80 0.76\n",
      "2 25 50 2 0.80 0.74\n",
      "2 25 50 4 0.82 0.74\n",
      "2 25 50 8 0.80 0.76\n",
      "2 25 50 16 0.80 0.77\n",
      "2 25 50 32 0.81 0.76\n",
      "2 25 auto 2 0.78 0.74\n",
      "2 25 auto 4 0.79 0.75\n",
      "2 25 auto 8 0.81 0.74\n",
      "2 25 auto 16 0.80 0.74\n",
      "2 25 auto 32 0.77 0.70\n",
      "[0.77941176 0.72058824 0.75       0.82089552 0.65151515]\n",
      "2 50 2 2 0.71 0.67\n",
      "2 50 2 4 0.74 0.70\n",
      "2 50 2 8 0.72 0.68\n",
      "2 50 2 16 0.73 0.67\n",
      "2 50 2 32 0.75 0.73\n",
      "2 50 4 2 0.77 0.75\n",
      "2 50 4 4 0.78 0.74\n",
      "2 50 4 8 0.76 0.73\n",
      "2 50 4 16 0.75 0.72\n",
      "2 50 4 32 0.77 0.75\n",
      "2 50 6 2 0.78 0.73\n",
      "2 50 6 4 0.78 0.73\n",
      "2 50 6 8 0.78 0.73\n",
      "2 50 6 16 0.77 0.74\n",
      "2 50 6 32 0.76 0.73\n",
      "2 50 8 2 0.80 0.73\n",
      "2 50 8 4 0.79 0.73\n",
      "2 50 8 8 0.79 0.73\n",
      "2 50 8 16 0.80 0.72\n",
      "2 50 8 32 0.78 0.76\n",
      "2 50 10 2 0.82 0.76\n",
      "2 50 10 4 0.77 0.71\n",
      "2 50 10 8 0.77 0.75\n",
      "2 50 10 16 0.80 0.72\n",
      "2 50 10 32 0.78 0.73\n",
      "2 50 15 2 0.80 0.75\n",
      "2 50 15 4 0.78 0.75\n",
      "2 50 15 8 0.81 0.72\n",
      "2 50 15 16 0.78 0.73\n",
      "2 50 15 32 0.80 0.75\n",
      "2 50 25 2 0.79 0.73\n",
      "2 50 25 4 0.80 0.73\n",
      "2 50 25 8 0.79 0.72\n",
      "2 50 25 16 0.79 0.74\n",
      "2 50 25 32 0.82 0.77\n",
      "2 50 50 2 0.81 0.76\n",
      "2 50 50 4 0.80 0.76\n",
      "2 50 50 8 0.80 0.78\n",
      "2 50 50 16 0.80 0.74\n",
      "2 50 50 32 0.80 0.76\n",
      "2 50 auto 2 0.80 0.73\n",
      "2 50 auto 4 0.78 0.75\n",
      "2 50 auto 8 0.80 0.72\n",
      "2 50 auto 16 0.80 0.76\n",
      "2 50 auto 32 0.79 0.74\n",
      "[0.77941176 0.70588235 0.77941176 0.79104478 0.62121212]\n",
      "2 100 2 2 0.74 0.71\n",
      "2 100 2 4 0.75 0.71\n",
      "2 100 2 8 0.73 0.69\n",
      "2 100 2 16 0.75 0.71\n",
      "2 100 2 32 0.74 0.72\n",
      "2 100 4 2 0.75 0.73\n",
      "2 100 4 4 0.77 0.74\n",
      "2 100 4 8 0.78 0.75\n",
      "2 100 4 16 0.77 0.72\n",
      "2 100 4 32 0.76 0.73\n",
      "2 100 6 2 0.77 0.73\n",
      "2 100 6 4 0.79 0.72\n",
      "2 100 6 8 0.78 0.74\n",
      "2 100 6 16 0.77 0.72\n",
      "2 100 6 32 0.75 0.75\n",
      "2 100 8 2 0.79 0.77\n",
      "2 100 8 4 0.78 0.75\n",
      "2 100 8 8 0.79 0.72\n",
      "2 100 8 16 0.78 0.72\n",
      "2 100 8 32 0.79 0.73\n",
      "2 100 10 2 0.78 0.74\n",
      "2 100 10 4 0.79 0.75\n",
      "2 100 10 8 0.79 0.72\n",
      "2 100 10 16 0.80 0.73\n",
      "2 100 10 32 0.78 0.76\n",
      "2 100 15 2 0.80 0.73\n",
      "2 100 15 4 0.77 0.71\n",
      "2 100 15 8 0.80 0.74\n",
      "2 100 15 16 0.79 0.73\n",
      "2 100 15 32 0.79 0.73\n",
      "2 100 25 2 0.80 0.73\n",
      "2 100 25 4 0.80 0.75\n",
      "2 100 25 8 0.81 0.73\n",
      "2 100 25 16 0.78 0.73\n",
      "2 100 25 32 0.80 0.74\n",
      "2 100 50 2 0.81 0.77\n",
      "2 100 50 4 0.80 0.73\n",
      "2 100 50 8 0.80 0.76\n",
      "2 100 50 16 0.82 0.75\n",
      "2 100 50 32 0.82 0.75\n",
      "2 100 auto 2 0.79 0.72\n",
      "2 100 auto 4 0.79 0.76\n",
      "2 100 auto 8 0.79 0.75\n",
      "2 100 auto 16 0.81 0.75\n",
      "2 100 auto 32 0.80 0.75\n",
      "[0.80882353 0.73529412 0.76470588 0.7761194  0.65151515]\n",
      "2 200 2 2 0.76 0.72\n",
      "2 200 2 4 0.74 0.73\n",
      "2 200 2 8 0.74 0.74\n",
      "2 200 2 16 0.74 0.73\n",
      "2 200 2 32 0.72 0.71\n",
      "2 200 4 2 0.75 0.73\n",
      "2 200 4 4 0.75 0.73\n",
      "2 200 4 8 0.79 0.75\n",
      "2 200 4 16 0.75 0.74\n",
      "2 200 4 32 0.77 0.73\n",
      "2 200 6 2 0.77 0.75\n",
      "2 200 6 4 0.77 0.73\n",
      "2 200 6 8 0.77 0.75\n",
      "2 200 6 16 0.76 0.73\n",
      "2 200 6 32 0.76 0.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-85db22e39241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m                                 \u001b[0mplot_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_te\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                                 \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_rf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                                 \u001b[0mbest_rf_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_rf_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                                 \u001b[0;31m#pickle.dumps(open('best_rf_cv.pkl',\"wb\"), best_rf_cv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 319\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \"\"\"\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[1;32m    128\u001b[0m                                     for p in self.estimator_params))\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[1;32m    182\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# Unbound method: the first parameter becomes positional-only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36mfrom_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m    578\u001b[0m         return cls(parameters,\n\u001b[1;32m    579\u001b[0m                    \u001b[0mreturn_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                    __validate_parameters__=False)\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 params = OrderedDict(((param.name, param)\n\u001b[0;32m--> 504\u001b[0;31m                                                 for param in parameters))\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m                     \u001b[0;31m# sentinel node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from matplotlib.mlab import griddata\n",
    "\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def printAccuracy(clf, Xtr, Xte):\n",
    "\ty_hat_test = clf.predict(Xte)\n",
    "\ty_hat_train = clf.predict(Xtr)\n",
    "\tacc_train =accuracy_score(y_train, y_hat_train)\n",
    "\tacc_test = accuracy_score(y_test,y_hat_test)\n",
    "\n",
    "\tprint('%.2f %.2f' % (acc_train, acc_test))\n",
    "\treturn acc_train, acc_test\n",
    "\n",
    "\n",
    "def plotCorrMap(ini, end):\n",
    "\tcorr = data[data.columns[ini:end+1]].corr()\n",
    "\tmask = np.zeros_like(corr)\n",
    "\tmask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\tax = sns.heatmap(corr.abs(), annot=True, fmt = '.1f', mask = mask,linewidths=.5)\n",
    "\tplt.tight_layout()\n",
    "\t#plt.savefig('teste.pdf')(salvar figura)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def plotCorrWithClass(ini, end, class_name):\n",
    "\tcorr = data[data.columns[ini:end+1]].corrwith(data[class_name])\n",
    "\tcorr.abs().plot(kind='bar')\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "data1 = pd.read_csv('data_arrhythmia.csv', sep = ';', na_values='?')\n",
    "data = data1.drop(data1[(data1['height'] > 250)].index) #retirei os valores invalidos de altura (700m)\n",
    "\n",
    "for col in data.columns:\n",
    "\tnum_null = data[col].isnull().sum()\n",
    "\tif num_null:\n",
    "\t\tprint('Column %s has %d (%.1f%%) null values' % (col, num_null, 100.0*num_null/data.shape[0]))\n",
    "\n",
    "for col in data.columns:\n",
    "\tnum_unique = np.unique(data[col])\n",
    "\tif len(num_unique) == 1:\n",
    "\t\tprint('Column %s has a single value and will be discarded' % (col))\n",
    "\t\tdata.drop(columns=[col], inplace = True)\n",
    "#data.diagnosis.value_counts().div(data.shape[0]/100.0).plot(kind='barh')\n",
    "#plt.show()\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "data.loc[data.diagnosis == 1, 'diagnosis'] = 0\n",
    "data.loc[data.diagnosis  > 1, 'diagnosis'] = 1\n",
    "\n",
    "print ('\\nBanco com %d amostras e %d colunas\\n' % data.shape)\n",
    "#data.target.shape\n",
    "\n",
    "print (\"Tabela sumarizando as colunas do banco\\n\")\n",
    "print (data.describe())\n",
    "\n",
    "X = data.loc[:, data.columns != 'diagnosis']\n",
    "y = data['diagnosis']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RF \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from joblib import dump, load    (No module named joblib)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "best_score = float('-inf')\n",
    "\n",
    "file_rf = open(\"Tuning_rf_acc.csv\",\"w\")\n",
    " \n",
    "plot_3d = []\n",
    "print(\"Testing Random Forests\")\n",
    "for max_depth in (1, 2, 3, 4, 5): \n",
    "\tfor n_estimators in [10, 25, 50, 100, 200]:\n",
    "\t\tfor max_features in [2, 4, 6, 8, 10, 15, 25, 50, \"auto\"]:\n",
    "\t\t\tfor min_samples_split in [2, 4, 8, 16, 32]:\n",
    "\t\t\t\tprint(max_depth, n_estimators, max_features, min_samples_split, end= ' ')\n",
    "\t\t\t\tclf = RF(max_depth = max_depth, n_estimators = n_estimators, max_features = max_features, min_samples_split = min_samples_split).fit(X_train, y_train)\n",
    "\t\t\t\tscore_tr, score_te = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\t\tif score_te > best_score:\n",
    "\t\t\t\t\tbest_score = score_te\n",
    "\t\t\t\t\tbest_rf = clone(clf)\n",
    "                    \n",
    "\t\t\t\t#acc = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\t\tplot_3d.append([n_estimators, max_depth, score_te])                    \n",
    "\t\t\t\tprint (max_depth, n_estimators, max_features, min_samples_split,file=file_rf)\n",
    "\t\t\t\tbest_rf_cv = cross_val_score(clf, X_train, y_train, cv=5) #dentro do for ou fora ?\n",
    "                print (best_rf_cv)\n",
    "\t\t\t\t#pickle.dumps(open('best_rf_cv.pkl',\"wb\"), best_rf_cv)                \n",
    "                \n",
    "plot_3d = np.array(plot_3d)\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "pltX, pltY = plot_3d[:,0], plot_3d[:,1]\n",
    "pltZ = plot_3d[:,-1]\n",
    "\n",
    "df = pd.DataFrame({'x': pltX, 'y': pltY, 'z': pltZ}, index=range(len(pltX)))\n",
    "\n",
    "surf = ax.plot_trisurf(df.x, df.y, df.z, cmap='jet', linewidth=0.1, edgecolor='k')\n",
    "ax.set_xlabel('N estimators')\n",
    "ax.set_ylabel('max_depth')\n",
    "ax.set_zlabel('Test accuracy')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "file_rf.close()\n",
    "    \n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "best_score = float('-inf')\n",
    "\n",
    "file_svm = open(\"Tuning_svm_acc.csv\",\"w\")\n",
    "\n",
    "plot_3d = []\n",
    "print(\"\\nTesting SVM\")\n",
    "for c in [0.125,0.25, 0.5, 1, 2, 4, 8, 16]:\n",
    "\tfor g in [0.0625, 0.125, 0.25, 0.5, 2, 4, 8, 16, 32, 'auto']:\n",
    "\t\tfor tol in [0.001, 0.006, 0.011, 0.016]:\n",
    "\t\t\tfor coef0 in [0, 0.01, 0.02, 0.03]:\n",
    "\t\t\t\tclf = SVC(C=c, gamma = g, tol = tol, coef0 = coef0, kernel = 'rbf').fit(X_train_scaled, y_train)\n",
    "\t\t\t\tprint(c, g, tol, coef0, end= ' ')\n",
    "\t\t\t\tscore_tr, score_te = printAccuracy(clf, X_train_scaled, X_test_scaled)\n",
    "\t\t\t\tif score_te > best_score:\n",
    "\t\t\t\t\tbest_score = score_te\n",
    "\t\t\t\t\tbest_svm = clone(clf)\n",
    "                    \n",
    "\t\t\t\t#acc = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\t\tplot_3d.append([c, tol, score_te])\n",
    "\t\t\t\tprint (c, g, tol, coef0,file=file_svm)\n",
    "\t\t\t\tbest_svm_cv = cross_val_score(clf, X_train, y_train, cv=5)                \n",
    "\t\t\t\t#pickle.dump(open('best_svm_cv.pkl',\"wb\"), best_svm_cv)\n",
    "                    \n",
    "plot_3d = np.array(plot_3d)\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "pltX, pltY = plot_3d[:,0], plot_3d[:,1]\n",
    "pltZ = plot_3d[:,-1]\n",
    "\n",
    "df = pd.DataFrame({'x': pltX, 'y': pltY, 'z': pltZ}, index=range(len(pltX)))\n",
    "\n",
    "surf = ax.plot_trisurf(df.x, df.y, df.z, cmap='jet', linewidth=0.1, edgecolor='k')\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('Tol')\n",
    "ax.set_zlabel('Test accuracy')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "file_svm.close()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "best_score = float('-inf')\n",
    "\n",
    "file_gbc = open(\"Tuning_gbc_acc.csv\",\"w\")\n",
    "\n",
    "plot_3d = []\n",
    "print(\"\\nTesting GBC\")\n",
    "for learning_rate in [0.0125, 0.025, 0.05, 0.1, 0.5, 1 ]:\n",
    "\tfor n_estimators in [10, 25, 50, 100, 200]:\n",
    "\t\tfor max_depth in [1, 2, 3, 4, 5]:\n",
    "\t\t\tfor max_leaf_nodes in [2, 5, 10, 20, 25]:\n",
    "\t\t\t\tclf = GBC(learning_rate = learning_rate, n_estimators = n_estimators, max_depth = max_depth, max_leaf_nodes = max_leaf_nodes ).fit(X_train_scaled, y_train)\n",
    "\t\t\t\tprint(learning_rate, n_estimators, max_depth, max_leaf_nodes, end= ' ')\n",
    "\t\t\t\tscore_tr, score_te = printAccuracy(clf, X_train_scaled, X_test_scaled)\n",
    "\t\t\t\tif score_te > best_score:\n",
    "\t\t\t\t\tbest_score = score_te\n",
    "\t\t\t\t\tbest_gbc = clone(clf)\n",
    "\n",
    "\t\t\t\t#acc = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\t\tplot_3d.append([learning_rate, n_estimators, score_te])\n",
    "\t\t\t\tprint (learning_rate, n_estimators, max_depth, max_leaf_nodes,file=file_gbc)\n",
    "\t\t\t\tbest_gbc_cv = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\t\t\t\t#pickle.dumps(open('best_gbc_cv.pkl',\"wb\"), best_gbc_cv)\n",
    "                    \n",
    "plot_3d = np.array(plot_3d)\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "pltX, pltY = plot_3d[:,0], plot_3d[:,1]\n",
    "pltZ = plot_3d[:,-1]\n",
    "\n",
    "df = pd.DataFrame({'x': pltX, 'y': pltY, 'z': pltZ}, index=range(len(pltX)))\n",
    "\n",
    "surf = ax.plot_trisurf(df.x, df.y, df.z, cmap='jet', linewidth=0.1, edgecolor='k')\n",
    "ax.set_xlabel('Learning rate')\n",
    "ax.set_ylabel('N estimators')\n",
    "ax.set_zlabel('Test accuracy')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "file_gbc.close()                    \n",
    "\n",
    "for col in data.columns[:14]:\n",
    "\n",
    "\tunique = np.unique(data[col])\n",
    "\tif len(unique) > 50:\n",
    "\t\thist0 = data.loc[data.diagnosis == 0, col].plot.density(alpha = 0.5, label = 'NEG', color = 'blue')\n",
    "\t\thist1 = data.loc[data.diagnosis == 1, col].plot.density(alpha = 0.5, label = 'POS', color = 'red')\n",
    "\telse:\n",
    "\t\thist0 = data.loc[data.diagnosis == 0, col].plot.hist(alpha = 0.5, label = 'NEG', color = 'blue')\n",
    "\t\thist1 = data.loc[data.diagnosis == 1, col].plot.hist(alpha = 0.5, label = 'POS', color = 'red')\n",
    "\tplt.xlabel(col)\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "plotCorrMap(0,14)\n",
    "plotCorrWithClass(0,14, 'diagnosis')\n",
    "\n",
    "plotCorrMap(15,26)\n",
    "plotCorrWithClass(15,26, 'diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
