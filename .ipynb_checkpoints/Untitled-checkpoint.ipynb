{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-11-07c95972a9b0>, line 77)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-07c95972a9b0>\"\u001b[0;36m, line \u001b[0;32m77\u001b[0m\n\u001b[0;31m    print(max_leaf_nodes, max_depth, min_samples_split, min_samples_leaf, end= ' ')\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def printAccuracy(clf, Xtr, Xte):\n",
    "\ty_hat_test = clf.predict(Xte)\n",
    "\ty_hat_train = clf.predict(Xtr)\n",
    "\tacc_train =accuracy_score(y_train, y_hat_train)\n",
    "\tacc_test = accuracy_score(y_test,y_hat_test)\n",
    "\n",
    "\tprint('%.2f %.2f' % (acc_train, acc_test))\n",
    "\treturn acc_train, acc_test\n",
    "\n",
    "\n",
    "def plotCorrMap(ini, end):\n",
    "\tcorr = data[data.columns[ini:end+1]].corr()\n",
    "\tmask = np.zeros_like(corr)\n",
    "\tmask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\tax = sns.heatmap(corr.abs(), annot=True, fmt = '.1f', mask = mask,linewidths=.5)\n",
    "\tplt.tight_layout()\n",
    "\t#plt.savefig('teste.pdf')(salvar figura)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def plotCorrWithClass(ini, end, class_name):\n",
    "\tcorr = data[data.columns[ini:end+1]].corrwith(data[class_name])\n",
    "\tcorr.abs().plot(kind='bar')\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "data = pd.read_csv('data_arrhythmia.csv', sep = ';', na_values='?')\n",
    "\n",
    "for col in data.columns:\n",
    "\tnum_null = data[col].isnull().sum()\n",
    "\tif num_null:\n",
    "\t\tprint('Column %s has %d (%.1f%%) null values' % (col, num_null, 100.0*num_null/data.shape[0]))\n",
    "\n",
    "for col in data.columns:\n",
    "\tnum_unique = np.unique(data[col])\n",
    "\tif len(num_unique) == 1:\n",
    "\t\tprint('Column %s has a single value and will be discarded' % (col))\n",
    "\t\tdata.drop(columns=[col], inplace = True)\n",
    "#data.diagnosis.value_counts().div(data.shape[0]/100.0).plot(kind='barh')\n",
    "#plt.show()\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "data.loc[data.diagnosis == 1, 'diagnosis'] = 0\n",
    "data.loc[data.diagnosis  > 1, 'diagnosis'] = 1\n",
    "\n",
    "X = data.loc[:, data.columns != 'diagnosis']\n",
    "y = data['diagnosis']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RF \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "best_score = float('-inf')\n",
    "\n",
    "print(\"Testing Random Forests\")\n",
    "for max_depth in range(1,10): \n",
    "\tfor max_leaf_nodes in [10]:\n",
    "\t\tfor min_samples_split in [2]:\n",
    "\t\t\tfor min_samples_leaf in [1]:\n",
    "\t\t\tprint(max_leaf_nodes, max_depth, min_samples_split, min_samples_leaf, end= ' ')\n",
    "\t\t\tclf = RF(n_estimators = 100, max_leaf_nodes = max_leaf_nodes, max_depth = max_depth, min_samples_split = min_samples_split,min_samples_leaf = min_samples_leaf).fit(X_train, y_train)\n",
    "\t\t\tscore_tr, score_te = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\tif score_te > best_score:\n",
    "\t\t\t\tbest_score = score_te\n",
    "\t\t\t\tbest_rf = clone(clf)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "best_score = float('-inf')\n",
    "print(\"\\nTesting SVM\")\n",
    "for c in [0.125,0.25, 0.5, 1, 2, 4, 8, 16]:\n",
    "\tfor degree in [3]:\n",
    "\t\tfor tol in [0.001]:\n",
    "\t\t\tfor coef0 in [0]:\n",
    "\t\t\tclf = SVC(C=c, degree = degree, tol = tol, coef0 = coef0, kernel = 'rbf', gamma = 'auto').fit(X_train_scaled, y_train)\n",
    "\t\t\tprint(c, degree, tol, coef0, end= ' ')\n",
    "\t\t\tscore_tr, score_te = printAccuracy(clf, X_train_scaled, X_test_scaled)\n",
    "\t\t\tif score_te > best_score:\n",
    "\t\t\t\tbest_score = score_te\n",
    "\t\t\t\tbest_svm = clone(clf)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "best_score = float('-inf')\n",
    "print(\"\\nTesting GBC\")\n",
    "for learning_rate in [0.0125, 0.025, 0.05, 0.1, 0.5, 1 ]:\n",
    "\tfor n_estimators in [100]:\n",
    "\t\tfor max_depth in [3]:\n",
    "\t\t\tfor max_leaf_nodes in [10]:\n",
    "\t\t\tclf = GBC(learning_rate = learning_rate, n_estimators = n_estimators, max_depth = max_depth, max_leaf_nodes = max_leaf_nodes ).fit(X_train_scaled, y_train)\n",
    "\t\t\tprint(learning_rate, n_estimators, max_depth, max_leaf_nodes, end= ' ')\n",
    "\t\t\tscore_tr, score_te = printAccuracy(clf, X_train_scaled, X_test_scaled)\n",
    "\t\t\tif score_te > best_score:\n",
    "\t\t\t\tbest_score = score_te\n",
    "\t\t\t\tbest_gbc = clone(clf)\n",
    "\n",
    "\n",
    "for col in data.columns[:14]:\n",
    "\n",
    "\tunique = np.unique(data[col])\n",
    "\tif len(unique) > 50:\n",
    "\t\thist0 = data.loc[data.diagnosis == 0, col].plot.density(alpha = 0.5, label = 'NEG', color = 'blue')\n",
    "\t\thist1 = data.loc[data.diagnosis == 1, col].plot.density(alpha = 0.5, label = 'POS', color = 'red')\n",
    "\telse:\n",
    "\t\thist0 = data.loc[data.diagnosis == 0, col].plot.hist(alpha = 0.5, label = 'NEG', color = 'blue')\n",
    "\t\thist1 = data.loc[data.diagnosis == 1, col].plot.hist(alpha = 0.5, label = 'POS', color = 'red')\n",
    "\tplt.xlabel(col)\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "plotCorrMap(0,14)\n",
    "plotCorrWithClass(0,14, 'diagnosis')\n",
    "\n",
    "plotCorrMap(15,26)\n",
    "plotCorrWithClass(15,26, 'diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
