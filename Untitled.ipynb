{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column T has 8 (1.8%) null values\n",
      "Column P has 22 (4.9%) null values\n",
      "Column QRST has 1 (0.2%) null values\n",
      "Column J has 376 (83.2%) null values\n",
      "Column heart_rate has 1 (0.2%) null values\n",
      "Column S'_wave has a single value and will be discarded\n",
      "Column CB has a single value and will be discarded\n",
      "Column CD has a single value and will be discarded\n",
      "Column CS has a single value and will be discarded\n",
      "Column EV has a single value and will be discarded\n",
      "Column EY has a single value and will be discarded\n",
      "Column FF has a single value and will be discarded\n",
      "Column FH has a single value and will be discarded\n",
      "Column FJ has a single value and will be discarded\n",
      "Column FL has a single value and will be discarded\n",
      "Column FS has a single value and will be discarded\n",
      "Column FZ has a single value and will be discarded\n",
      "Column GA has a single value and will be discarded\n",
      "Column GH has a single value and will be discarded\n",
      "Column IB has a single value and will be discarded\n",
      "Column KP has a single value and will be discarded\n",
      "Column LC has a single value and will be discarded\n",
      "Testing Random Forests\n",
      "1 10 2 8 0.68 0.56\n",
      "1 10 4 8 0.64 0.55\n",
      "1 10 8 8 0.65 0.59\n",
      "1 10 16 8 0.69 0.58\n",
      "1 10 32 8 0.66 0.58\n",
      "1 10 2 8 0.68 0.56\n",
      "1 10 4 8 0.74 0.61\n",
      "1 10 8 8 0.69 0.58\n",
      "1 10 16 8 0.73 0.59\n",
      "1 10 32 8 0.69 0.57\n",
      "1 10 2 8 0.72 0.55\n",
      "1 10 4 8 0.77 0.60\n",
      "1 10 8 8 0.74 0.59\n",
      "1 10 16 8 0.69 0.64\n",
      "1 10 32 8 0.77 0.66\n",
      "1 10 2 8 0.70 0.56\n",
      "1 10 4 8 0.74 0.61\n",
      "1 10 8 8 0.72 0.59\n",
      "1 10 16 8 0.71 0.62\n",
      "1 10 32 8 0.73 0.63\n",
      "1 10 2 8 0.76 0.63\n",
      "1 10 4 8 0.75 0.57\n",
      "1 10 8 8 0.73 0.60\n",
      "1 10 16 8 0.71 0.58\n",
      "1 10 32 8 0.72 0.56\n",
      "1 10 2 8 0.74 0.62\n",
      "1 10 4 8 0.72 0.58\n",
      "1 10 8 8 0.73 0.57\n",
      "1 10 16 8 0.73 0.58\n",
      "1 10 32 8 0.74 0.61\n",
      "1 10 2 8 0.72 0.61\n",
      "1 10 4 8 0.75 0.59\n",
      "1 10 8 8 0.76 0.59\n",
      "1 10 16 8 0.72 0.58\n",
      "1 10 32 8 0.75 0.62\n",
      "1 10 2 8 0.73 0.64\n",
      "1 10 4 8 0.79 0.62\n",
      "1 10 8 8 0.75 0.65\n",
      "1 10 16 8 0.71 0.63\n",
      "1 10 32 8 0.79 0.59\n",
      "1 10 2 8 0.69 0.59\n",
      "1 10 4 8 0.73 0.61\n",
      "1 10 8 8 0.75 0.60\n",
      "1 10 16 8 0.71 0.58\n",
      "1 10 32 8 0.73 0.58\n",
      "1 25 2 8 0.62 0.53\n",
      "1 25 4 8 0.67 0.55\n",
      "1 25 8 8 0.68 0.57\n",
      "1 25 16 8 0.66 0.53\n",
      "1 25 32 8 0.66 0.58\n",
      "1 25 2 8 0.69 0.56\n",
      "1 25 4 8 0.68 0.56\n",
      "1 25 8 8 0.70 0.58\n",
      "1 25 16 8 0.69 0.57\n",
      "1 25 32 8 0.69 0.58\n",
      "1 25 2 8 0.69 0.58\n",
      "1 25 4 8 0.73 0.58\n",
      "1 25 8 8 0.72 0.58\n",
      "1 25 16 8 0.73 0.62\n",
      "1 25 32 8 0.71 0.60\n",
      "1 25 2 8 0.71 0.58\n",
      "1 25 4 8 0.75 0.61\n",
      "1 25 8 8 0.73 0.61\n",
      "1 25 16 8 0.74 0.58\n",
      "1 25 32 8 0.73 0.62\n",
      "1 25 2 8 0.75 0.58\n",
      "1 25 4 8 0.73 0.58\n",
      "1 25 8 8 0.75 0.63\n",
      "1 25 16 8 0.74 0.61\n",
      "1 25 32 8 0.73 0.58\n",
      "1 25 2 8 0.76 0.65\n",
      "1 25 4 8 0.74 0.62\n",
      "1 25 8 8 0.74 0.65\n",
      "1 25 16 8 0.74 0.60\n",
      "1 25 32 8 0.75 0.58\n",
      "1 25 2 8 0.75 0.63\n",
      "1 25 4 8 0.75 0.59\n",
      "1 25 8 8 0.77 0.63\n",
      "1 25 16 8 0.75 0.60\n",
      "1 25 32 8 0.77 0.61\n",
      "1 25 2 8 0.76 0.63\n",
      "1 25 4 8 0.77 0.64\n",
      "1 25 8 8 0.76 0.62\n",
      "1 25 16 8 0.75 0.58\n",
      "1 25 32 8 0.77 0.66\n",
      "1 25 2 8 0.75 0.59\n",
      "1 25 4 8 0.73 0.62\n",
      "1 25 8 8 0.75 0.65\n",
      "1 25 16 8 0.70 0.59\n",
      "1 25 32 8 0.74 0.64\n",
      "1 50 2 8 0.68 0.56\n",
      "1 50 4 8 0.68 0.53\n",
      "1 50 8 8 0.65 0.58\n",
      "1 50 16 8 0.63 0.54\n",
      "1 50 32 8 0.67 0.58\n",
      "1 50 2 8 0.71 0.58\n",
      "1 50 4 8 0.72 0.58\n",
      "1 50 8 8 0.70 0.61\n",
      "1 50 16 8 0.68 0.54\n",
      "1 50 32 8 0.69 0.58\n",
      "1 50 2 8 0.74 0.60\n",
      "1 50 4 8 0.74 0.61\n",
      "1 50 8 8 0.73 0.60\n",
      "1 50 16 8 0.70 0.58\n",
      "1 50 32 8 0.71 0.56\n",
      "1 50 2 8 0.75 0.61\n",
      "1 50 4 8 0.74 0.57\n",
      "1 50 8 8 0.71 0.58\n",
      "1 50 16 8 0.71 0.56\n",
      "1 50 32 8 0.73 0.61\n",
      "1 50 2 8 0.72 0.61\n",
      "1 50 4 8 0.75 0.60\n",
      "1 50 8 8 0.74 0.59\n",
      "1 50 16 8 0.72 0.61\n",
      "1 50 32 8 0.73 0.59\n",
      "1 50 2 8 0.75 0.60\n",
      "1 50 4 8 0.76 0.65\n",
      "1 50 8 8 0.74 0.58\n",
      "1 50 16 8 0.72 0.60\n",
      "1 50 32 8 0.74 0.59\n",
      "1 50 2 8 0.75 0.62\n",
      "1 50 4 8 0.76 0.59\n",
      "1 50 8 8 0.76 0.60\n",
      "1 50 16 8 0.77 0.62\n",
      "1 50 32 8 0.73 0.59\n",
      "1 50 2 8 0.74 0.61\n",
      "1 50 4 8 0.74 0.60\n",
      "1 50 8 8 0.74 0.62\n",
      "1 50 16 8 0.78 0.65\n",
      "1 50 32 8 0.77 0.62\n",
      "1 50 2 8 0.75 0.60\n",
      "1 50 4 8 0.74 0.62\n",
      "1 50 8 8 0.72 0.60\n",
      "1 50 16 8 0.73 0.63\n",
      "1 50 32 8 0.73 0.60\n",
      "1 100 2 8 0.67 0.58\n",
      "1 100 4 8 0.68 0.57\n",
      "1 100 8 8 0.63 0.53\n",
      "1 100 16 8 0.66 0.57\n",
      "1 100 32 8 0.68 0.57\n",
      "1 100 2 8 0.70 0.58\n",
      "1 100 4 8 0.70 0.57\n",
      "1 100 8 8 0.69 0.58\n",
      "1 100 16 8 0.70 0.58\n",
      "1 100 32 8 0.72 0.60\n",
      "1 100 2 8 0.74 0.60\n",
      "1 100 4 8 0.72 0.58\n",
      "1 100 8 8 0.73 0.58\n",
      "1 100 16 8 0.73 0.59\n",
      "1 100 32 8 0.73 0.59\n",
      "1 100 2 8 0.72 0.60\n",
      "1 100 4 8 0.73 0.58\n",
      "1 100 8 8 0.73 0.59\n",
      "1 100 16 8 0.75 0.58\n",
      "1 100 32 8 0.75 0.61\n",
      "1 100 2 8 0.74 0.59\n",
      "1 100 4 8 0.75 0.60\n",
      "1 100 8 8 0.76 0.60\n",
      "1 100 16 8 0.74 0.58\n",
      "1 100 32 8 0.74 0.60\n",
      "1 100 2 8 0.73 0.61\n",
      "1 100 4 8 0.74 0.60\n",
      "1 100 8 8 0.74 0.62\n",
      "1 100 16 8 0.74 0.61\n",
      "1 100 32 8 0.75 0.61\n",
      "1 100 2 8 0.76 0.64\n",
      "1 100 4 8 0.75 0.62\n",
      "1 100 8 8 0.74 0.63\n",
      "1 100 16 8 0.76 0.62\n",
      "1 100 32 8 0.76 0.63\n",
      "1 100 2 8 0.76 0.62\n",
      "1 100 4 8 0.76 0.65\n",
      "1 100 8 8 0.75 0.63\n",
      "1 100 16 8 0.76 0.63\n",
      "1 100 32 8 0.77 0.62\n",
      "1 100 2 8 0.77 0.63\n",
      "1 100 4 8 0.73 0.62\n",
      "1 100 8 8 0.75 0.62\n",
      "1 100 16 8 0.74 0.59\n",
      "1 100 32 8 0.74 0.63\n",
      "1 200 2 8 0.63 0.54\n",
      "1 200 4 8 0.67 0.56\n",
      "1 200 8 8 0.67 0.58\n",
      "1 200 16 8 0.66 0.56\n",
      "1 200 32 8 0.65 0.53\n",
      "1 200 2 8 0.69 0.56\n",
      "1 200 4 8 0.71 0.62\n",
      "1 200 8 8 0.71 0.58\n",
      "1 200 16 8 0.71 0.59\n",
      "1 200 32 8 0.69 0.56\n",
      "1 200 2 8 0.73 0.58\n",
      "1 200 4 8 0.73 0.58\n",
      "1 200 8 8 0.72 0.58\n",
      "1 200 16 8 0.72 0.57\n",
      "1 200 32 8 0.73 0.60\n",
      "1 200 2 8 0.75 0.60\n",
      "1 200 4 8 0.73 0.62\n",
      "1 200 8 8 0.74 0.61\n",
      "1 200 16 8 0.74 0.60\n",
      "1 200 32 8 0.73 0.59\n",
      "1 200 2 8 0.73 0.61\n",
      "1 200 4 8 0.74 0.60\n",
      "1 200 8 8 0.73 0.61\n",
      "1 200 16 8 0.75 0.61\n",
      "1 200 32 8 0.75 0.61\n",
      "1 200 2 8 0.73 0.63\n",
      "1 200 4 8 0.75 0.62\n",
      "1 200 8 8 0.74 0.61\n",
      "1 200 16 8 0.73 0.59\n",
      "1 200 32 8 0.74 0.59\n",
      "1 200 2 8 0.74 0.61\n",
      "1 200 4 8 0.75 0.62\n",
      "1 200 8 8 0.75 0.60\n",
      "1 200 16 8 0.75 0.64\n",
      "1 200 32 8 0.76 0.62\n",
      "1 200 2 8 0.76 0.63\n",
      "1 200 4 8 0.76 0.63\n",
      "1 200 8 8 0.75 0.61\n",
      "1 200 16 8 0.76 0.65\n",
      "1 200 32 8 0.76 0.63\n",
      "1 200 2 8 0.74 0.60\n",
      "1 200 4 8 0.74 0.64\n",
      "1 200 8 8 0.75 0.61\n",
      "1 200 16 8 0.75 0.61\n",
      "1 200 32 8 0.75 0.63\n",
      "2 10 2 8 0.73 0.62\n",
      "2 10 4 8 0.72 0.57\n",
      "2 10 8 8 0.77 0.61\n",
      "2 10 16 8 0.73 0.64\n",
      "2 10 32 8 0.72 0.58\n",
      "2 10 2 8 0.76 0.61\n",
      "2 10 4 8 0.75 0.58\n",
      "2 10 8 8 0.76 0.61\n",
      "2 10 16 8 0.78 0.61\n",
      "2 10 32 8 0.76 0.60\n",
      "2 10 2 8 0.76 0.58\n",
      "2 10 4 8 0.78 0.66\n",
      "2 10 8 8 0.76 0.58\n",
      "2 10 16 8 0.78 0.61\n",
      "2 10 32 8 0.79 0.66\n",
      "2 10 2 8 0.78 0.58\n",
      "2 10 4 8 0.78 0.63\n",
      "2 10 8 8 0.75 0.58\n",
      "2 10 16 8 0.75 0.56\n",
      "2 10 32 8 0.75 0.64\n",
      "2 10 2 8 0.80 0.61\n",
      "2 10 4 8 0.78 0.59\n",
      "2 10 8 8 0.81 0.60\n",
      "2 10 16 8 0.76 0.59\n",
      "2 10 32 8 0.82 0.62\n",
      "2 10 2 8 0.79 0.66\n",
      "2 10 4 8 0.77 0.64\n",
      "2 10 8 8 0.78 0.65\n",
      "2 10 16 8 0.80 0.66\n",
      "2 10 32 8 0.80 0.57\n",
      "2 10 2 8 0.77 0.65\n",
      "2 10 4 8 0.78 0.65\n",
      "2 10 8 8 0.77 0.64\n",
      "2 10 16 8 0.79 0.67\n",
      "2 10 32 8 0.80 0.66\n",
      "2 10 2 8 0.79 0.63\n",
      "2 10 4 8 0.83 0.65\n",
      "2 10 8 8 0.82 0.70\n",
      "2 10 16 8 0.80 0.71\n",
      "2 10 32 8 0.82 0.66\n",
      "2 10 2 8 0.79 0.66\n",
      "2 10 4 8 0.75 0.63\n",
      "2 10 8 8 0.77 0.62\n",
      "2 10 16 8 0.80 0.67\n",
      "2 10 32 8 0.77 0.61\n",
      "2 25 2 8 0.74 0.57\n",
      "2 25 4 8 0.74 0.60\n",
      "2 25 8 8 0.76 0.63\n",
      "2 25 16 8 0.73 0.57\n",
      "2 25 32 8 0.71 0.59\n",
      "2 25 2 8 0.78 0.62\n",
      "2 25 4 8 0.78 0.60\n",
      "2 25 8 8 0.77 0.60\n",
      "2 25 16 8 0.78 0.62\n",
      "2 25 32 8 0.76 0.62\n",
      "2 25 2 8 0.81 0.62\n",
      "2 25 4 8 0.79 0.65\n",
      "2 25 8 8 0.78 0.65\n",
      "2 25 16 8 0.78 0.65\n",
      "2 25 32 8 0.79 0.63\n",
      "2 25 2 8 0.78 0.65\n",
      "2 25 4 8 0.79 0.60\n",
      "2 25 8 8 0.77 0.62\n",
      "2 25 16 8 0.79 0.65\n",
      "2 25 32 8 0.81 0.65\n",
      "2 25 2 8 0.80 0.62\n",
      "2 25 4 8 0.83 0.66\n",
      "2 25 8 8 0.81 0.64\n",
      "2 25 16 8 0.81 0.63\n",
      "2 25 32 8 0.82 0.67\n",
      "2 25 2 8 0.81 0.67\n",
      "2 25 4 8 0.83 0.65\n",
      "2 25 8 8 0.78 0.62\n",
      "2 25 16 8 0.79 0.63\n",
      "2 25 32 8 0.81 0.66\n",
      "2 25 2 8 0.83 0.65\n",
      "2 25 4 8 0.80 0.65\n",
      "2 25 8 8 0.81 0.65\n",
      "2 25 16 8 0.83 0.65\n",
      "2 25 32 8 0.83 0.70\n",
      "2 25 2 8 0.83 0.69\n",
      "2 25 4 8 0.83 0.69\n",
      "2 25 8 8 0.84 0.69\n",
      "2 25 16 8 0.83 0.65\n",
      "2 25 32 8 0.83 0.65\n",
      "2 25 2 8 0.81 0.64\n",
      "2 25 4 8 0.81 0.67\n",
      "2 25 8 8 0.83 0.67\n",
      "2 25 16 8 0.82 0.65\n",
      "2 25 32 8 0.79 0.59\n",
      "2 50 2 8 0.73 0.61\n",
      "2 50 4 8 0.73 0.60\n",
      "2 50 8 8 0.76 0.63\n",
      "2 50 16 8 0.75 0.61\n",
      "2 50 32 8 0.75 0.55\n",
      "2 50 2 8 0.76 0.61\n",
      "2 50 4 8 0.76 0.58\n",
      "2 50 8 8 0.78 0.58\n",
      "2 50 16 8 0.76 0.62\n",
      "2 50 32 8 0.79 0.65\n",
      "2 50 2 8 0.78 0.65\n",
      "2 50 4 8 0.81 0.62\n",
      "2 50 8 8 0.78 0.62\n",
      "2 50 16 8 0.79 0.62\n",
      "2 50 32 8 0.78 0.62\n",
      "2 50 2 8 0.80 0.67\n",
      "2 50 4 8 0.81 0.63\n",
      "2 50 8 8 0.79 0.61\n",
      "2 50 16 8 0.79 0.65\n",
      "2 50 32 8 0.78 0.65\n",
      "2 50 2 8 0.78 0.65\n",
      "2 50 4 8 0.80 0.63\n",
      "2 50 8 8 0.81 0.64\n",
      "2 50 16 8 0.80 0.65\n",
      "2 50 32 8 0.81 0.65\n",
      "2 50 2 8 0.81 0.67\n",
      "2 50 4 8 0.82 0.67\n",
      "2 50 8 8 0.81 0.62\n",
      "2 50 16 8 0.80 0.63\n",
      "2 50 32 8 0.84 0.68\n",
      "2 50 2 8 0.83 0.66\n",
      "2 50 4 8 0.83 0.70\n",
      "2 50 8 8 0.81 0.65\n",
      "2 50 16 8 0.82 0.66\n",
      "2 50 32 8 0.82 0.67\n",
      "2 50 2 8 0.83 0.70\n",
      "2 50 4 8 0.83 0.65\n",
      "2 50 8 8 0.83 0.66\n",
      "2 50 16 8 0.83 0.67\n",
      "2 50 32 8 0.83 0.65\n",
      "2 50 2 8 0.81 0.67\n",
      "2 50 4 8 0.82 0.67\n",
      "2 50 8 8 0.81 0.63\n",
      "2 50 16 8 0.82 0.71\n",
      "2 50 32 8 0.83 0.65\n",
      "2 100 2 8 0.75 0.60\n",
      "2 100 4 8 0.75 0.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 100 8 8 0.73 0.60\n",
      "2 100 16 8 0.75 0.60\n",
      "2 100 32 8 0.75 0.59\n",
      "2 100 2 8 0.76 0.61\n",
      "2 100 4 8 0.80 0.61\n",
      "2 100 8 8 0.77 0.60\n",
      "2 100 16 8 0.78 0.62\n",
      "2 100 32 8 0.76 0.62\n",
      "2 100 2 8 0.78 0.60\n",
      "2 100 4 8 0.79 0.65\n",
      "2 100 8 8 0.79 0.61\n",
      "2 100 16 8 0.78 0.58\n",
      "2 100 32 8 0.81 0.66\n",
      "2 100 2 8 0.79 0.61\n",
      "2 100 4 8 0.80 0.66\n",
      "2 100 8 8 0.79 0.62\n",
      "2 100 16 8 0.80 0.62\n",
      "2 100 32 8 0.80 0.63\n",
      "2 100 2 8 0.82 0.65\n",
      "2 100 4 8 0.82 0.65\n",
      "2 100 8 8 0.80 0.65\n",
      "2 100 16 8 0.81 0.63\n",
      "2 100 32 8 0.80 0.64\n",
      "2 100 2 8 0.80 0.65\n",
      "2 100 4 8 0.82 0.66\n",
      "2 100 8 8 0.81 0.65\n",
      "2 100 16 8 0.83 0.68\n",
      "2 100 32 8 0.81 0.68\n",
      "2 100 2 8 0.82 0.65\n",
      "2 100 4 8 0.84 0.65\n",
      "2 100 8 8 0.84 0.68\n",
      "2 100 16 8 0.82 0.65\n",
      "2 100 32 8 0.81 0.66\n",
      "2 100 2 8 0.84 0.66\n",
      "2 100 4 8 0.84 0.69\n",
      "2 100 8 8 0.82 0.65\n",
      "2 100 16 8 0.84 0.65\n",
      "2 100 32 8 0.84 0.68\n",
      "2 100 2 8 0.81 0.65\n",
      "2 100 4 8 0.81 0.70\n",
      "2 100 8 8 0.82 0.69\n",
      "2 100 16 8 0.81 0.64\n",
      "2 100 32 8 0.80 0.64\n",
      "2 200 2 8 0.76 0.61\n",
      "2 200 4 8 0.75 0.62\n",
      "2 200 8 8 0.76 0.64\n",
      "2 200 16 8 0.75 0.62\n",
      "2 200 32 8 0.73 0.58\n",
      "2 200 2 8 0.79 0.62\n",
      "2 200 4 8 0.77 0.62\n",
      "2 200 8 8 0.79 0.62\n",
      "2 200 16 8 0.77 0.62\n",
      "2 200 32 8 0.79 0.60\n",
      "2 200 2 8 0.81 0.65\n",
      "2 200 4 8 0.79 0.60\n",
      "2 200 8 8 0.78 0.60\n",
      "2 200 16 8 0.81 0.65\n",
      "2 200 32 8 0.79 0.59\n",
      "2 200 2 8 0.79 0.61\n",
      "2 200 4 8 0.78 0.60\n",
      "2 200 8 8 0.81 0.63\n",
      "2 200 16 8 0.80 0.61\n",
      "2 200 32 8 0.81 0.66\n",
      "2 200 2 8 0.81 0.65\n",
      "2 200 4 8 0.81 0.62\n",
      "2 200 8 8 0.81 0.63\n",
      "2 200 16 8 0.81 0.62\n",
      "2 200 32 8 0.79 0.63\n",
      "2 200 2 8 0.81 0.64\n",
      "2 200 4 8 0.82 0.64\n",
      "2 200 8 8 0.82 0.65\n",
      "2 200 16 8 0.80 0.63\n",
      "2 200 32 8 0.80 0.63\n",
      "2 200 2 8 0.82 0.66\n",
      "2 200 4 8 0.83 0.66\n",
      "2 200 8 8 0.82 0.64\n",
      "2 200 16 8 0.81 0.65\n",
      "2 200 32 8 0.82 0.68\n",
      "2 200 2 8 0.84 0.68\n",
      "2 200 4 8 0.83 0.68\n",
      "2 200 8 8 0.84 0.68\n",
      "2 200 16 8 0.83 0.69\n",
      "2 200 32 8 0.83 0.68\n",
      "2 200 2 8 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-57410bb1faca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                                 \u001b[0mscore_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprintAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mscore_te\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 319\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0m_set_random_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mto_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# grouped by prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[1;32m    182\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# Unbound method: the first parameter becomes positional-only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36mfrom_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m    578\u001b[0m         return cls(parameters,\n\u001b[1;32m    579\u001b[0m                    \u001b[0mreturn_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                    __validate_parameters__=False)\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 params = OrderedDict(((param.name, param)\n\u001b[0;32m--> 504\u001b[0;31m                                                 for param in parameters))\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_setitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/_abcoll.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    569\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/renandrades/.local/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((param,))\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 params = OrderedDict(((param.name, param)\n\u001b[0;32m--> 504\u001b[0;31m                                                 for param in parameters))\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.mlab import griddata\n",
    "\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def printAccuracy(clf, Xtr, Xte):\n",
    "\ty_hat_test = clf.predict(Xte)\n",
    "\ty_hat_train = clf.predict(Xtr)\n",
    "\tacc_train =accuracy_score(y_train, y_hat_train)\n",
    "\tacc_test = accuracy_score(y_test,y_hat_test)\n",
    "\n",
    "\tprint('%.2f %.2f' % (acc_train, acc_test))\n",
    "\treturn acc_train, acc_test\n",
    "\n",
    "\n",
    "def plotCorrMap(ini, end):\n",
    "\tcorr = data[data.columns[ini:end+1]].corr()\n",
    "\tmask = np.zeros_like(corr)\n",
    "\tmask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\tax = sns.heatmap(corr.abs(), annot=True, fmt = '.1f', mask = mask,linewidths=.5)\n",
    "\tplt.tight_layout()\n",
    "\t#plt.savefig('teste.pdf')(salvar figura)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def plotCorrWithClass(ini, end, class_name):\n",
    "\tcorr = data[data.columns[ini:end+1]].corrwith(data[class_name])\n",
    "\tcorr.abs().plot(kind='bar')\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "data = pd.read_csv('data_arrhythmia.csv', sep = ';', na_values='?')\n",
    "\n",
    "for col in data.columns:\n",
    "\tnum_null = data[col].isnull().sum()\n",
    "\tif num_null:\n",
    "\t\tprint('Column %s has %d (%.1f%%) null values' % (col, num_null, 100.0*num_null/data.shape[0]))\n",
    "\n",
    "for col in data.columns:\n",
    "\tnum_unique = np.unique(data[col])\n",
    "\tif len(num_unique) == 1:\n",
    "\t\tprint('Column %s has a single value and will be discarded' % (col))\n",
    "\t\tdata.drop(columns=[col], inplace = True)\n",
    "#data.diagnosis.value_counts().div(data.shape[0]/100.0).plot(kind='barh')\n",
    "#plt.show()\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "data.loc[data.diagnosis == 1, 'diagnosis'] = 0\n",
    "data.loc[data.diagnosis  > 1, 'diagnosis'] = 1\n",
    "\n",
    "X = data.loc[:, data.columns != 'diagnosis']\n",
    "y = data['diagnosis']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RF \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "best_score = float('-inf')\n",
    "\n",
    "file_rf = open(\"Tuning_rf_acc.csv\",\"w\")\n",
    " \n",
    "plot_3d = []\n",
    "print(\"Testing Random Forests\")\n",
    "for max_depth in (1, 2, 3, 4, 5): \n",
    "\tfor n_estimators in [10, 25, 50, 100, 200]:\n",
    "\t\tfor max_features in [2, 4, 6, 8, 10, 15, 25, 50, \"auto\"]:\n",
    "\t\t\tfor min_samples_split in [2, 4, 8, 16, 32]:\n",
    "\t\t\t\tprint(max_depth, n_estimators, min_samples_split, min_samples_leaf, end= ' ')\n",
    "\t\t\t\tclf = RF(n_estimators = n_estimators, max_depth = max_depth, min_samples_split = min_samples_split, max_features = max_features).fit(X_train, y_train)\n",
    "\t\t\t\tscore_tr, score_te = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\t\tif score_te > best_score:\n",
    "\t\t\t\t\tbest_score = score_te\n",
    "\t\t\t\t\tbest_rf = clone(clf)\n",
    "                    \n",
    "\t\t\t\t#acc = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\t\tplot_3d.append([n_estimators, max_depth, score_te])                    \n",
    "\t\t\t\tprint (max_depth, n_estimators, max_features, min_samples_split,file=file_rf)\n",
    "                \n",
    "plot_3d = np.array(plot_3d)\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "pltX, pltY = plot_3d[:,0], plot_3d[:,1]\n",
    "pltZ = plot_3d[:,-1]\n",
    "\n",
    "df = pd.DataFrame({'x': pltX, 'y': pltY, 'z': pltZ}, index=range(len(pltX)))\n",
    "\n",
    "surf = ax.plot_trisurf(df.x, df.y, df.z, cmap='jet', linewidth=0.1, edgecolor='k')\n",
    "ax.set_xlabel('N estimators')\n",
    "ax.set_ylabel('max_depth')\n",
    "ax.set_zlabel('Test accuracy')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "file_rf.close()\n",
    "    \n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "best_score = float('-inf')\n",
    "\n",
    "file_svm = open(\"Tuning_svm_acc.csv\",\"w\")\n",
    "\n",
    "plot_3d = []\n",
    "print(\"\\nTesting SVM\")\n",
    "for c in [0.125,0.25, 0.5, 1, 2, 4, 8, 16]:\n",
    "\tfor g in [0.0625, 0.125, 0.25, 0.5, 2, 4, 8, 16, 32, 'auto']:\n",
    "\t\tfor tol in [0.001, 0.006, 0.011, 0.016]:\n",
    "\t\t\tfor coef0 in [0, 0.01, 0.02, 0.03]:\n",
    "\t\t\t\tclf = SVC(C=c, tol = tol, coef0 = coef0, kernel = 'rbf', gamma = g).fit(X_train_scaled, y_train)\n",
    "\t\t\t\tprint(c, g, tol, coef0, end= ' ')\n",
    "\t\t\t\tscore_tr, score_te = printAccuracy(clf, X_train_scaled, X_test_scaled)\n",
    "\t\t\t\tif score_te > best_score:\n",
    "\t\t\t\t\tbest_score = score_te\n",
    "\t\t\t\t\tbest_svm = clone(clf)\n",
    "                    \n",
    "\t\t\t\t#acc = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\t\tplot_3d.append([c, tol, score_te])\n",
    "\t\t\t\tprint (c, g, tol, coef0,file=file_svm)\n",
    "                    \n",
    "plot_3d = np.array(plot_3d)\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "pltX, pltY = plot_3d[:,0], plot_3d[:,1]\n",
    "pltZ = plot_3d[:,-1]\n",
    "\n",
    "df = pd.DataFrame({'x': pltX, 'y': pltY, 'z': pltZ}, index=range(len(pltX)))\n",
    "\n",
    "surf = ax.plot_trisurf(df.x, df.y, df.z, cmap='jet', linewidth=0.1, edgecolor='k')\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('Tol')\n",
    "ax.set_zlabel('Test accuracy')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "file_svm.close()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "best_score = float('-inf')\n",
    "\n",
    "file_gbc = open(\"Tuning_gbc_acc.csv\",\"w\")\n",
    "\n",
    "plot_3d = []\n",
    "print(\"\\nTesting GBC\")\n",
    "for learning_rate in [0.0125, 0.025, 0.05, 0.1, 0.5, 1 ]:\n",
    "\tfor n_estimators in [10, 25, 50, 100, 200]:\n",
    "\t\tfor max_depth in [1, 2, 3, 4, 5]:\n",
    "\t\t\tfor max_leaf_nodes in [2, 5, 10, 20, 25]:\n",
    "\t\t\t\tclf = GBC(learning_rate = learning_rate, n_estimators = n_estimators, max_depth = max_depth, max_leaf_nodes = max_leaf_nodes ).fit(X_train_scaled, y_train)\n",
    "\t\t\t\tprint(learning_rate, n_estimators, max_depth, max_leaf_nodes, end= ' ')\n",
    "\t\t\t\tscore_tr, score_te = printAccuracy(clf, X_train_scaled, X_test_scaled)\n",
    "\t\t\t\tif score_te > best_score:\n",
    "\t\t\t\t\tbest_score = score_te\n",
    "\t\t\t\t\tbest_gbc = clone(clf)\n",
    "\n",
    "\t\t\t\t#acc = printAccuracy(clf, X_train, X_test)\n",
    "\t\t\t\tplot_3d.append([learning_rate, n_estimators, score_te])\n",
    "\t\t\t\tprint (learning_rate, n_estimators, max_depth, max_leaf_nodes,file=file_gbc)                \n",
    "                    \n",
    "plot_3d = np.array(plot_3d)\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "pltX, pltY = plot_3d[:,0], plot_3d[:,1]\n",
    "pltZ = plot_3d[:,-1]\n",
    "\n",
    "df = pd.DataFrame({'x': pltX, 'y': pltY, 'z': pltZ}, index=range(len(pltX)))\n",
    "\n",
    "surf = ax.plot_trisurf(df.x, df.y, df.z, cmap='jet', linewidth=0.1, edgecolor='k')\n",
    "ax.set_xlabel('Learning rate')\n",
    "ax.set_ylabel('N estimators')\n",
    "ax.set_zlabel('Test accuracy')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "file_gbc.close()                    \n",
    "\n",
    "for col in data.columns[:14]:\n",
    "\n",
    "\tunique = np.unique(data[col])\n",
    "\tif len(unique) > 50:\n",
    "\t\thist0 = data.loc[data.diagnosis == 0, col].plot.density(alpha = 0.5, label = 'NEG', color = 'blue')\n",
    "\t\thist1 = data.loc[data.diagnosis == 1, col].plot.density(alpha = 0.5, label = 'POS', color = 'red')\n",
    "\telse:\n",
    "\t\thist0 = data.loc[data.diagnosis == 0, col].plot.hist(alpha = 0.5, label = 'NEG', color = 'blue')\n",
    "\t\thist1 = data.loc[data.diagnosis == 1, col].plot.hist(alpha = 0.5, label = 'POS', color = 'red')\n",
    "\tplt.xlabel(col)\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "plotCorrMap(0,14)\n",
    "plotCorrWithClass(0,14, 'diagnosis')\n",
    "\n",
    "plotCorrMap(15,26)\n",
    "plotCorrWithClass(15,26, 'diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
